{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training_set = pd.read_csv('../Dataset/training_set.csv', sep=';')\n",
    "testing_set = pd.read_csv('../Dataset/testing_set.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset normalized\n",
    "training_set_norm = pd.read_csv('../Dataset/training_set_normalized_y.csv', sep=';')\n",
    "testing_set_norm = pd.read_csv('../Dataset/testing_set_normalized_y.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of each feature by y\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.scatter(training_set['hw1'], training_set['y'])\n",
    "plt.xlabel('hw1')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.scatter(training_set['hw2'], training_set['y'])\n",
    "plt.xlabel('hw2')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.scatter(training_set['tw'], training_set['y'])\n",
    "plt.xlabel('tw')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.scatter(training_set['bf1'], training_set['y'])\n",
    "plt.xlabel('bf1')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.scatter(training_set['bf2'], training_set['y'])\n",
    "plt.xlabel('bf2')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.scatter(training_set['tf1'], training_set['y'])\n",
    "plt.xlabel('tf1')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.scatter(training_set['tf2'], training_set['y'])\n",
    "plt.xlabel('tf2')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.scatter(training_set['psi'], training_set['y'])\n",
    "plt.xlabel('psi')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.scatter(training_set['L'], training_set['y'])\n",
    "plt.xlabel('L')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of each feature by y normalized\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.scatter(training_set_norm['hw1'], training_set_norm['y'])\n",
    "plt.xlabel('hw1')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.scatter(training_set_norm['hw2'], training_set_norm['y'])\n",
    "plt.xlabel('hw2')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.scatter(training_set_norm['tw'], training_set_norm['y'])\n",
    "plt.xlabel('tw')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.scatter(training_set_norm['bf1'], training_set_norm['y'])\n",
    "plt.xlabel('bf1')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.scatter(training_set_norm['bf2'], training_set_norm['y'])\n",
    "plt.xlabel('bf2')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.scatter(training_set_norm['tf1'], training_set_norm['y'])\n",
    "plt.xlabel('tf1')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.scatter(training_set_norm['tf2'], training_set_norm['y'])\n",
    "plt.xlabel('tf2')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.scatter(training_set_norm['psi'], training_set_norm['y'])\n",
    "plt.xlabel('psi')\n",
    "plt.ylabel('y')\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.scatter(training_set_norm['L'], training_set_norm['y'])\n",
    "plt.xlabel('L')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix heatmap\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "corr = training_set_norm.corr()\n",
    "hm = sns.heatmap(round(corr, 2), annot=True, ax=ax, cmap=\"coolwarm\", fmt='.2f',\n",
    "                 linewidths=.05)\n",
    "f.subplots_adjust(top=0.93)\n",
    "t = f.suptitle('Correlation Heatmap', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "\n",
    "* Activation function is the hyperbolic tangent function\n",
    "\n",
    "* Loss function is the mean squared error\n",
    "\n",
    "* Optimizer is the stochastic gradient descent\n",
    "\n",
    "* Network architecture: 9 x 18 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 12:37:43.619752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 12:37:43.972302: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 12:37:44.038421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-28 12:37:44.038447: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-28 12:37:45.204007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-28 12:37:45.204182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-28 12:37:45.204191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res = backend.sum(backend.square(y_true - y_pred))\n",
    "    SS_tot = backend.sum(backend.square(y_true - backend.mean(y_true)))\n",
    "    return 1 - SS_res / (SS_tot + backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1893/1893 [==============================] - 3s 2ms/step - loss: 2.6896 - r_squared: -0.0506 - val_loss: 2.7188 - val_r_squared: -0.0326\n",
      "Epoch 2/2\n",
      "1893/1893 [==============================] - 3s 2ms/step - loss: 2.6465 - r_squared: -0.0329 - val_loss: 2.7082 - val_r_squared: -0.0202\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=9, activation='tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[r_squared])\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(training_set_norm.drop(['y'], axis=1), training_set_norm['y'], epochs=10000, batch_size=32, verbose=1, validation_data=(testing_set_norm.drop(['y'], axis=1), testing_set_norm['y']))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.708162784576416\n",
      "Test accuracy: -0.020226847380399704\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(testing_set_norm.drop(['y'], axis=1), testing_set_norm['y'], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(history.history.keys())\n",
    "# # Plot the training history\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['r_squared'])\n",
    "# plt.plot(history.history['val_r_squared'])\n",
    "# plt.title('R^2')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('R^2')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "# plt.show()\n",
    "\n",
    "# # Evaluate the model\n",
    "# scores = model.evaluate(testing_set_norm.drop(['y'], axis=1), testing_set_norm['y'])\n",
    "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrenn\n",
    "\n",
    "# Convert the model to pyrenn\n",
    "pyrenn_model = pyrenn.CreateNN([9, 18, 1])\n",
    "\n",
    "P = training_set_norm.drop(['y'], axis=1).values\n",
    "Y = training_set_norm['y'].values\n",
    "\n",
    "P = P.T\n",
    "Y = Y.reshape(1, -1)\n",
    "\n",
    "pyrenn.train_LM(P, Y, pyrenn_model, E_stop=1e-5, k_max=500, verbose=True)\n",
    "\n",
    "# save the model\n",
    "pyrenn.saveNN(pyrenn_model, 'pyrenn_model')\n",
    "\n",
    "# Predict the output of the testing set\n",
    "y_pred = pyrenn.NNOut(testing_set_norm.drop(['y'], axis=1).values.T, pyrenn_model)\n",
    "\n",
    "# Plot the predicted output of the testing set\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(testing_set_norm['y'], label='Testing set')\n",
    "plt.plot(y_pred, label='Prediction')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Mean squared error: %.2f' % mean_squared_error(testing_set_norm['y'], y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(testing_set_norm['y'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the predicted output on th training set by the real output\n",
    "# R^2 on the legend\n",
    "plt.scatter(training_set_norm['y'], pyrenn.NNOut(training_set_norm.drop(['y'], axis=1).values.T, pyrenn_model))\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Real output')\n",
    "plt.ylabel('Predicted output')\n",
    "r2 = r2_score(training_set_norm['y'], pyrenn.NNOut(training_set_norm.drop(['y'], axis=1).values.T, pyrenn_model))\n",
    "plt.legend(['R^2 = ' + str(r2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the predicted by the real output of the testing set\n",
    "plt.scatter(testing_set_norm['y'], y_pred)\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Predicted')\n",
    "r2 = r2_score(testing_set_norm['y'], y_pred)\n",
    "plt.legend(['R^2 = ' + str(r2)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrenn\n",
    "\n",
    "# Convert the model to pyrenn\n",
    "pyrenn_model1 = pyrenn.CreateNN([9, 64, 64, 1])\n",
    "\n",
    "P = training_set_norm.drop(['y'], axis=1).values\n",
    "Y = training_set_norm['y'].values\n",
    "\n",
    "P = P.T\n",
    "Y = Y.reshape(1, -1)\n",
    "\n",
    "pyrenn.train_LM(P, Y, pyrenn_model1, E_stop=1e-5, k_max=500, verbose=True)\n",
    "\n",
    "# save the model\n",
    "pyrenn.saveNN(pyrenn_model1, 'pyrenn_model1')\n",
    "\n",
    "# Predict the output of the testing set\n",
    "y_pred1 = pyrenn.NNOut(testing_set_norm.drop(['y'], axis=1).values.T, pyrenn_model1)\n",
    "\n",
    "# Plot the predicted output of the testing set\n",
    "plt.plot(testing_set_norm['y'], label='Testing set')\n",
    "plt.plot(y_pred1, label='Prediction')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Mean squared error: %.2f' % mean_squared_error(testing_set_norm['y'], y_pred1))\n",
    "print('Coefficient of determination: %.2f' % r2_score(testing_set_norm['y'], y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the predicted output on th training set by the real output\n",
    "# R^2 on the legend\n",
    "plt.scatter(training_set_norm['y'], pyrenn.NNOut(training_set_norm.drop(['y'], axis=1).values.T, pyrenn_model1))\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Real output')\n",
    "plt.ylabel('Predicted output')\n",
    "r2 = r2_score(training_set_norm['y'], pyrenn.NNOut(training_set_norm.drop(['y'], axis=1).values.T, pyrenn_model1))\n",
    "plt.legend(['R^2 = ' + str(r2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the predicted by the real output of the testing set\n",
    "plt.scatter(testing_set_norm['y'], y_pred1)\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Predicted')\n",
    "r2 = r2_score(testing_set_norm['y'], y_pred1)\n",
    "plt.legend(['R^2 = ' + str(r2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrenn\n",
    "\n",
    "# # Convert the model to pyrenn\n",
    "# pyrenn_model2 = pyrenn.CreateNN([9, 128, 16, 1])\n",
    "\n",
    "# P = training_set_norm.drop(['y'], axis=1).values\n",
    "# Y = training_set_norm['y'].values\n",
    "\n",
    "# P = P.T\n",
    "# Y = Y.reshape(1, -1)\n",
    "\n",
    "# train2 = pyrenn.train_LM(P, Y, pyrenn_model2, E_stop=1e-5, k_max=500, verbose=True)\n",
    "\n",
    "# # save the model\n",
    "# pyrenn.saveNN(pyrenn_model2, 'pyrenn_model2')\n",
    "\n",
    "# save the train2 object\n",
    "import pickle\n",
    "pickle.dump(train2, open('train2.pkl', 'wb'))\n",
    "\n",
    "# Predict the output of the testing set\n",
    "y_pred = pyrenn.NNOut(testing_set_norm.drop(['y'], axis=1).values.T, pyrenn_model2)\n",
    "\n",
    "# Plot the predicted output of the testing set\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(testing_set_norm['y'], label='Testing set')\n",
    "plt.plot(y_pred, label='Prediction')\n",
    "plt.title('Prediction')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Mean squared error: %.2f' % mean_squared_error(testing_set_norm['y'], y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(testing_set_norm['y'], y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train2 object and plot the error history\n",
    "import pickle\n",
    "train2 = pickle.load(open('train2.pkl', 'rb'))\n",
    "\n",
    "# Plot the error history\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(train2['ErrorHistory'])\n",
    "plt.title('Error history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
