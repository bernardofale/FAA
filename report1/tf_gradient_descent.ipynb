{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "X = np.load('archive-2/Sign-language-digits-dataset/X.npy')\n",
    "\n",
    "# flatten the X matrix\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "Y = np.zeros((X.shape[0], 10))\n",
    "Y[0:204, 9] = 1\n",
    "Y[204:409, 0] = 1\n",
    "Y[409:615, 7] = 1\n",
    "Y[615:822, 6] = 1\n",
    "Y[822:1028, 1] = 1\n",
    "Y[1028:1236, 8] = 1\n",
    "Y[1236:1443, 4] = 1\n",
    "Y[1443:1649, 3] = 1\n",
    "Y[1649:1855, 2] = 1\n",
    "Y[1855:, 5] = 1\n",
    "\n",
    "indices = np.argmax(Y, axis=1)\n",
    "Y = np.expand_dims(indices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 23:30:00.930117: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = np.concatenate((Y, X), axis=1)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Extract features (pixel values) and labels\n",
    "X = data[:, 1:]  # Pixel values\n",
    "y = data[:, 0]   # Labels\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = to_categorical(y, num_classes=10)  # Assuming you have 10 classes (digits 0 to 9)\n",
    "\n",
    "# Now, 'X' contains the pixel values, and 'y_one_hot' contains the one-hot encoded labels\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2025)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation and testing sets (you may need to adjust the split ratio)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.1, random_state=42)\n",
    "\n",
    "# Now, you can use X_train and y_train to train your neural network, and X_test and y_test for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 23:30:06.742208: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 150)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m X_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mreshape(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m45\u001b[39m, \u001b[39m45\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Create the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m model \u001b[39m=\u001b[39m build_model(input_dim, hidden_layer_sizes, output_dim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Train the model using custom gradient descent\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m cost_history, gradients \u001b[39m=\u001b[39m custom_gradient_descent(model, X_train, y_train, learning_rate, num_iterations)\n",
      "\u001b[1;32m/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m hidden_units \u001b[39min\u001b[39;00m hidden_layer_sizes:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(hidden_units, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(filters\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m45\u001b[39m, \u001b[39m45\u001b[39m, \u001b[39m1\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(output_dim, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/FAA/FAA/report1/tf_gradient_descent.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 253\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 150)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(input_dim, hidden_layer_sizes, output_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    for hidden_units in hidden_layer_sizes:\n",
    "        model.add(tf.keras.layers.Dense(hidden_units, activation='relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(output_dim, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Function to perform feed-forward, calculate cost, do backpropagation, and return gradients\n",
    "def train_step(model, X_train, y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_train, training=True)\n",
    "        loss_value = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_train, y_pred))\n",
    "    \n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    \n",
    "    return loss_value, grads\n",
    "\n",
    "# Function to perform gradient descent with a custom model\n",
    "def custom_gradient_descent(model, X_train, y_train, learning_rate, num_iterations):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    cost_history = []\n",
    "    for i in range(num_iterations):\n",
    "        loss_value, grads = train_step(model, X_train, y_train)\n",
    "        \n",
    "        # Apply gradients\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        cost_history.append(loss_value.numpy())\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Iteration {i+1}/{num_iterations}, Loss: {loss_value.numpy()}')\n",
    "    \n",
    "    return cost_history, grads\n",
    "\n",
    "# Example usage\n",
    "input_dim = 2025\n",
    "hidden_layer_sizes = [150, 100, 50]\n",
    "output_dim = 10\n",
    "learning_rate = 0.3\n",
    "num_iterations = 1000\n",
    "\n",
    "# Create the model\n",
    "model = build_model(input_dim, hidden_layer_sizes, output_dim)\n",
    "\n",
    "# Train the model using custom gradient descent\n",
    "cost_history, gradients = custom_gradient_descent(model, X_train, y_train, learning_rate, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_one_hot = np.argmax(y_pred, axis=1)\n",
    "y_test_one_hot = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(y_pred_one_hot == y_test_one_hot)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss over epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_random_image_and_predict(model, X, y, class_labels):\n",
    "    # Select a random index from the training set\n",
    "    random_index = np.random.randint(0, len(X))\n",
    "    \n",
    "    # Get the image and true label\n",
    "    random_image = X[random_index]\n",
    "    true_label = y[random_index]\n",
    "    \n",
    "    # Reshape the image if it's flattened\n",
    "    if random_image.shape != (45, 45):\n",
    "        random_image = random_image.reshape(45, 45)\n",
    "    \n",
    "    # Make a prediction using the model\n",
    "    predicted = model.predict(random_image.reshape(1, -1))\n",
    "    predicted_label = np.argmax(predicted)\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(random_image, cmap='gray')\n",
    "    plt.title(f\"True Label: {class_labels[np.argmax(true_label)]}\\nPredicted Label: {class_labels[predicted_label]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"True Label: {class_labels[np.argmax(true_label)]}\\nPredicted Label: {class_labels[predicted_label]}\")\n",
    "# Assuming you have a list of class labels\n",
    "class_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "print(y_test.shape)\n",
    "# Call the function to display a random image and make a prediction\n",
    "plot_random_image_and_predict(model, X_test, y_test, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
